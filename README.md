本プラグインは、動画・静止画内の人物の顔を隠すAfter Effectsプラグインです。  
人物の顔を自動で認識し、その上にマスク画像を被せます。  
マスク画像は人物の顔の位置を自動で追従します。


**⚠️Macでしか動かないと思います⚠️**


## 感謝

### YOLO v8

人物の認識、追従にはこちらを使用しています。  
すばらしい精度のライブラリ、モデルを提供してくださることに感謝します。  
https://docs.ultralytics.com/ja/


### Bolt CEP

CEPプロジェクトの構築にはこちらを使用しています。  
多大な苦痛の大いなる軽減に感謝します。  
https://github.com/hyperbrew/bolt-cep


## 検証環境

下記環境で検証しています。  
それ以外の環境でも動くかもしれませんが、Windowsではたぶん動かないと思います。

- MacBook Air (M1, 2020)
- macOS Monterey (12.6.7)
- Adobe After Effects 2024
- Python 3.11.2
- 30fps


## インストール

本プラグインはトラッキングにYOLO v8を使用しています。  
このため、Pythonの実行環境が必要です。

### Pythonのインストール

Pythonをグローバルにインストールしてください（具体的な手順はGoogle検索等でご確認ください）。  
After Effectsから外部コマンドを起動する場合、パスが /usr/bin:/bin:/usr/sbin:/sbin にしか通ってないようなのでインストール先に注意してください。  
特に、pyenvなどのバージョン管理ツールを使用している場合はcommand not foundになるかもしれません（なりました）。  
その場合は仮想環境を使用してください（後述）。

### Pythonライブラリのインストール

下記ライブラリをグローバルにインストールしてください。

```sh
pip install ultralytics scikit-learn
```

### Pythonの仮想環境を使用したい場合

適当な場所に仮想環境を作成して各種インストールを行い、設定でその環境を指定してください。

### 本プラグインのインストール

検証できたら書きます。。。


## 使用方法

1. ウィンドウ → エクステンション → Face Trackerを選択し、Face Trackerのパネルを表示します。
2. プロジェクトパネルでマスクに使用する画像を選択し、Face Trackerパネルで「マスク画像」の「選択」ボタンを押下します。
3. プロジェクトパネルでトラッキングする動画または静止画を右クリックし、「選択範囲から新規コンポジション」を選択します。
4. タイムラインパネルで上記で作成したコンポジションを開き、トラッキングする動画または静止画のレイヤーを選択します。
5. Face Trackerパネルで「トラッキング開始」ボタンをクリックします。
6. トラッキングが開始されるので、終了を待ちます。諸条件にもよりますが、とても時間がかかります。
7. トラッキングが終了すると、タイムラインパネルにマスクが追加されます。

### 「選択範囲から新規コンポジション」について

この操作は必須ではありません。  
以下の条件を満たす任意のコンポジションを利用できます。  

- コンポジションのサイズが動画のサイズと一致していること。
- コンポジションのフレームレートが動画のフレームレートと一致していること。
- コンポジションのデュレーションが動画のデュレーションと一致していること。
- 動画または静止画が0フレームから開始すること。
- 動画がトリミングされていないこと。

手っ取り早くこの条件を満たせるのが「選択範囲から新規コンポジション」だということです。

### プラグインフォルダ

本プラグインはプロジェクトに「nyankomaher-face-tracker」というフォルダを作成します。
このフォルダを削除、変更しないでください。



## 設定

| 設定             | 説明                                                                                                                                                                | 
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | 
| プリセット       | 新規ボタンを押下して現在の設定を保存できます。保存した設定はプルダウンで選択し、適用ボタンを押下することで適用できます（プルダウンを変更しただけでは適用されません）。                                              | 
| 解析サイズ       | 映像を解析する際、映像をここで指定した幅にリサイズして解析します。サイズを大きくすれば精度は向上しますが、解析時間は長くなります。                                  | 
| 解析間隔         | 映像を解析する際、ここで指定したフレーム数に1回解析を行います。間隔を大きくすれば解析時間を短縮できますが、精度は低下します。                                       | 
| 重複領域閾値     | 検出した複数の人物領域に重なりがある場合、この値以上重なっている場合は同一の人物とみなします（IoU）。                                                             | 
| 確信度閾値       | 映像を解析する際、どの程度の確信があれば人物として検出するかの閾値です。                                                                                            | 
| マスク画像拡張   | マスクの画像をこの値の倍率で拡大・縮小できます。この値が1のとき、マスク画像の幅は人物の幅と同じです。                                                                          | 
| マスク時間拡張   | マスクの表示時間をこの値の秒数分、延長・短縮できます。延長すると、トラッキングの開始と終了が不安定になりやすくなります。この値が1のとき、マスク画像は人物の検出開始と検出終了に合わせて表示されます。                                       | 
| 最小マスクサイズ | マスクはここで指定した幅より小さくなりません。                                                                                                                  | 
| マスク位置補間  | マスクのXY座標の補間法です。                                                                                                                                        | 
| マスクサイズ補間 | マスクのサイズの補間法です。                                                                                                                                        | 
| Python         | Pythonの仮想環境を使用する場合、ここにpythonのフルパスを入力してください（例：/path/to/your/venv/bin/python）。                                                                                        | 
| スクリプト       | モデルを変更したい、トラッキングの設定を変えたい、人間以外を追従したい、GPUを使いたいなどの場合、 src/js/public/bin/track.py をカスタマイズして、独自の人物認識・追従を実装することができます。その場合、ここにカスタマイズしたファイルのフルパスを入力してください。 | 


## 注意点

### 精度

本プラグインでは100%の精度で顔を隠すことを想定して作られていません。  
ある程度自動化し、手動で仕上げることを想定しています。  
また、本プラグインは街や観光地で撮影した動画に映り込む人を隠すことを想定してチューニングしています。  
それとは異なる種類の動画では精度が落ちるかもしれません。  

### 動作ロジックと苦手なシチュエーション

本プラグインはFace Trackerと名乗ってはいますが、人物の顔を検出しているわけではなく、人物の体全体を検出しています。  
（顔の検出では遠くの人物、横や後ろから見た顔などの検出精度に満足できなかったのでこのようになりました）  
そして検出した領域の上側、頭がありそうな位置にマスクを配置します。  
マスクの幅は検出した人物の幅と同じです。  
したがって、座っている人を横から撮った映像など、人物が直立していない場面では検出領域の幅が大きくなり（曲げている足も含めて検出するため）、マスクのサイズも実際の顔の領域より大きくなります。  
また、人物が画面端に見切れていくときは実際の人物の幅より検出領域の幅が狭くなり、安定してトラッキングできないことがあります。  

### 登場人物の多い映像

本プラグインは映像に登場する人物1人につき1個の画像レイヤーを追加します。  
登場人物の多い映像ではAfter Effectsの動作が不安定になったり、レンダリングに時間がかかったりするかもしれません。

### 開発

Bolt Cepを使用しています。  
初回だけ、yarn devの前にyarn buildする必要があるようです。



## ライセンス

AGPL-3.0